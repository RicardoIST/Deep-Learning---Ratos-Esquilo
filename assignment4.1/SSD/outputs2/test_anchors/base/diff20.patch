On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   configs/test_anchors/base.py
	modified:   requirements.txt
	modified:   ssd/modeling/backbones/basic.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	datasets/

no changes added to commit (use "git add" and/or "git commit -a")
fc8dff9707ebd557422cbb26302646531fc51511
diff --git a/assignment4.1/SSD/configs/test_anchors/base.py b/assignment4.1/SSD/configs/test_anchors/base.py
index 8929e60..acfaff5 100644
--- a/assignment4.1/SSD/configs/test_anchors/base.py
+++ b/assignment4.1/SSD/configs/test_anchors/base.py
@@ -23,7 +23,7 @@ train.imshape = (128, 1024)
 
 
 anchors = L(AnchorBoxes)(
-    feature_sizes=[[32, 256], [16, 128], [8, 64], [4, 32], [2, 16], [1, 8]],
+    feature_sizes= [[32, 256], [16, 128], [8, 64], [4, 32], [2, 16], [1, 8]],
     # Strides is the number of pixels (in image space) between each spatial position in the feature map
     strides= [[4, 4], [8, 8], [16, 16], [32, 32], [64, 64], [128, 128]],
     min_sizes=[[16, 16], [32, 32], [48, 48], [64, 64], [86, 86], [128, 128], [128, 400]],
diff --git a/assignment4.1/SSD/requirements.txt b/assignment4.1/SSD/requirements.txt
index 77ae212..8b325e7 100644
--- a/assignment4.1/SSD/requirements.txt
+++ b/assignment4.1/SSD/requirements.txt
@@ -1,6 +1,6 @@
-Cython>=0.28.
-scikit-image
-ujson
+Cython>=0.28. #yes
+scikit-image #yes
+ujson #yes
 pybind11
 git+https://github.com/NVIDIA/cocoapi.git@v0.6.0#subdirectory=PythonAPI
 pycocotools==2.0.0
diff --git a/assignment4.1/SSD/ssd/modeling/backbones/basic.py b/assignment4.1/SSD/ssd/modeling/backbones/basic.py
index 91ef094..48df662 100644
--- a/assignment4.1/SSD/ssd/modeling/backbones/basic.py
+++ b/assignment4.1/SSD/ssd/modeling/backbones/basic.py
@@ -1,3 +1,4 @@
+import torch
 from torch import nn
 from typing import Tuple, List
 
@@ -18,20 +19,14 @@ class BasicModel(torch.nn.Module):
             image_channels: int,
             output_feature_sizes: List[Tuple[int]]):
         super().__init__()
+
+
         self.out_channels = output_channels
         self.output_feature_shape = output_feature_sizes
-
-        self.out_features = nn.Sequential(
-            nn.Conv2d(
-                in_channels=image_channels,
-                out_channels=32,
-                kernel_size=3,
-                stride=1,
-                padding=1
-            ),
+        self.feature_extractor = nn.Sequential(
+            nn.Conv2d(image_channels, 32, kernel_size=3, padding=1, stride=1),
             nn.ReLU(),
-            nn.MaxPool2d(kernel_size=2, stride=2),
-
+            nn.MaxPool2d(kernel_size=2,stride=2), 
             nn.Conv2d(
                 in_channels=32,
                 out_channels=64,
@@ -48,6 +43,7 @@ class BasicModel(torch.nn.Module):
                 padding=1
             ),
             nn.ReLU(),
+            # Use ceil mode to get 75/2 to ouput 38#sol
             nn.Conv2d(
                 in_channels=64,
                 out_channels=output_channels[0],
@@ -56,121 +52,104 @@ class BasicModel(torch.nn.Module):
                 padding=1
             ),
             nn.ReLU(),
-
-            #module 1 up
-
-            nn.Conv2d(
-                in_channels=output_channels[0],
-                out_channels=128,
-                kernel_size=3,
-                stride=1,
-                padding=1
+        ) #sol
+
+        self.additional_layers = nn.ModuleList([#sol
+            nn.Sequential( # 19 x 19 out#sol
+                nn.Conv2d(
+                    in_channels=output_channels[0],
+                    out_channels=128,
+                    kernel_size=3,
+                    stride=1,
+                    padding=1
+                ),
+                nn.ReLU(),
+                nn.Conv2d(
+                    in_channels=128,
+                    out_channels=output_channels[1],
+                    kernel_size=3,
+                    stride=2,
+                    padding=1
+                ),
+                nn.ReLU(),#sol
+            ),#sol
+            nn.Sequential( 
+                nn.Conv2d(
+                    in_channels=output_channels[1],
+                    out_channels=256,
+                    kernel_size=3,
+                    stride=1,
+                    padding=1
+                ),
+                nn.ReLU(),
+                nn.Conv2d(
+                    in_channels=256,
+                    out_channels=output_channels[2],
+                    kernel_size=3,
+                    stride=2,
+                    padding=1
+                ),
+                nn.ReLU(),#sol
+            ),#sol
+            nn.Sequential( # 5 x 5 out#sol
+                nn.Conv2d(
+                    in_channels=output_channels[2],
+                    out_channels=128,
+                    kernel_size=3,
+                    stride=1,
+                    padding=1
+                ),
+                nn.ReLU(),#sol
+                nn.Conv2d(
+                    in_channels=128,
+                    out_channels=output_channels[3],
+                    kernel_size=3,
+                    stride=2,
+                    padding=1
+                ),
+                nn.ReLU(),
+            ),#sol
+            nn.Sequential( 
+                nn.Conv2d(
+                    in_channels=output_channels[3],
+                    out_channels=128,
+                    kernel_size=3,
+                    stride=1,
+                    padding=1
+                ),
+                nn.ReLU(),
+                nn.Conv2d(
+                    in_channels=128,
+                    out_channels=output_channels[4],
+                    kernel_size=3,
+                    stride=2,
+                    padding=1
+                ),
+                nn.ReLU(),
+                
             ),
-            nn.ReLU(),
-            nn.Conv2d(
-                in_channels=128,
-                out_channels=output_channels[1],
-                kernel_size=3,
-                stride=2,
-                padding=1
-            ),
-            nn.ReLU(),
             
-            #module 2 up
-
-            nn.Conv2d(
-                in_channels=output_channels[1],
-                out_channels=256,
-                kernel_size=3,
-                stride=1,
-                padding=1
-            ),
-            nn.ReLU(),
-            nn.Conv2d(
-                in_channels=256,
-                out_channels=output_channels[2],
-                kernel_size=3,
-                stride=2,
-                padding=1
-            ),
-            nn.ReLU(),
-
-            #Module 3 up
-
-            nn.Conv2d(
-                in_channels=output_channels[2],
-                out_channels=128,
-                kernel_size=3,
-                stride=1,
-                padding=1
-            ),
-            nn.ReLU(),
-            nn.Conv2d(
-                in_channels=128,
-                out_channels=output_channels[3],
-                kernel_size=3,
-                stride=2,
-                padding=1
-            ),
-            nn.ReLU(),
-
-            #Module 4 up
-
-            nn.Conv2d(
-                in_channels=output_channels[3],
-                out_channels=128,
-                kernel_size=3,
-                stride=1,
-                padding=1
-            ),
-            nn.ReLU(),
-            nn.Conv2d(
-                in_channels=128,
-                out_channels=output_channels[3],
-                kernel_size=3,
-                stride=2,
-                padding=1
-            ),
-            nn.ReLU(),
-            
-            #Module 5 up
-
-            nn.Conv2d(
-                in_channels=output_channels[3],
-                out_channels=128,
-                kernel_size=3,
-                stride=1,
-                padding=1
-            ),
-            nn.ReLU(),
-            nn.Conv2d(
-                in_channels=128,
-                out_channels=output_channels[4],
-                kernel_size=3,
-                stride=2,
-                padding=1
-            ),
-            nn.ReLU(),
-
-            #Module 6 up
-
-            nn.Conv2d(
-                in_channels=output_channels[4],
-                out_channels=128,
-                kernel_size=2,
-                stride=1,
-                padding=1
-            ),
-            nn.ReLU(),
-            nn.Conv2d(
-                in_channels=128,
-                out_channels=output_channels[5],
-                kernel_size=2,
-                stride=1,
-                padding=0
-            ),
-            nn.ReLU(),
-        )
+            nn.Sequential(
+                nn.Conv2d(
+                    in_channels=output_channels[4],
+                    out_channels=128,
+                    kernel_size=3,
+                    stride=1,
+                    padding=1
+                ),
+                nn.ReLU(),
+                nn.Conv2d(
+                    in_channels=128,
+                    out_channels=output_channels[5],
+                    kernel_size=3,
+                    stride=2,
+                    padding=1
+                ),
+                nn.ReLU(),
+            ),
+        ])
+
+        
 
     def forward(self, x):
         """
@@ -185,11 +164,18 @@ class BasicModel(torch.nn.Module):
         where out_features[0] should have the shape:
             shape(-1, output_channels[0], 38, 38),
         """
+
         out_features = []
+        x = self.feature_extractor(x)
+        out_features.append(x)
+        for additional_layer in self.additional_layers.children():
+            x = additional_layer(x)
+            out_features.append(x)
         for idx, feature in enumerate(out_features):
             out_channel = self.out_channels[idx]
             h, w = self.output_feature_shape[idx]
             expected_shape = (out_channel, h, w)
+            print("The expected shape: "+ str(expected_shape)+" got "+str(feature.shape[1:]))
             assert feature.shape[1:] == expected_shape, \
                 f"Expected shape: {expected_shape}, got: {feature.shape[1:]} at output IDX: {idx}"
         assert len(out_features) == len(self.output_feature_shape),\
